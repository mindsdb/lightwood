{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smooth-philip",
   "metadata": {},
   "source": [
    "### Custom Encoder: Rule-Based\n",
    "\n",
    "Lightwood uses \"Encoders\" to convert preprocessed (cleaned) data into **features**. Encoders represent the **feature engineering** step of the data science pipeline; they can either have a set of instructions (\"rule-based\") or a learned representation (trained on data).\n",
    "\n",
    "In the following notebook, we will experiment with creating a custom encoder that creates **Label Encoding**. \n",
    "\n",
    "For example, imagine we have the following set of categories:\n",
    "\n",
    "```\n",
    "MyColumnData = [\"apple\", \"orange\", \"orange\", \"banana\", \"apple\", \"dragonfruit\"]\n",
    "```\n",
    "\n",
    "There are 4 categories to consider: \"apple\", \"banana\", \"orange\", and \"dragonfruit\".\n",
    "\n",
    "**Label encoding** allows you to refer to these categories as if they were numbers. For example, consider the mapping (arranged alphabetically):\n",
    "\n",
    "1 - apple <br>\n",
    "2 - banana <br>\n",
    "3 - dragonfruit <br>\n",
    "4 - orange <br>\n",
    "\n",
    "Using this mapping, we can convert the above data as follows:\n",
    "\n",
    "```\n",
    "MyFeatureData = [1, 4, 4, 2, 1, 3]\n",
    "```\n",
    "\n",
    "In the following notebook, we will design a **LabelEncoder** for Lightwood for use on categorical data. We will be using the Kaggle \"Used Car\" [dataset](https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes). We've provided a link for you to automatically access this CSV. This dataset describes various details of cars on sale - with the goal of predicting how much this car may sell for.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-adventure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:36.493568Z",
     "iopub.status.busy": "2022-02-03T21:30:36.493252Z",
     "iopub.status.idle": "2022-02-03T21:30:37.976228Z",
     "shell.execute_reply": "2022-02-03T21:30:37.975946Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lightwood modules\n",
    "import lightwood as lw\n",
    "from lightwood import ProblemDefinition, \\\n",
    "                      JsonAI, \\\n",
    "                      json_ai_from_problem, \\\n",
    "                      code_from_json_ai, \\\n",
    "                      predictor_from_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-income",
   "metadata": {},
   "source": [
    "### 1) Load your data\n",
    "\n",
    "Lightwood works with `pandas.DataFrame`s; load data via pandas as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-government",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:37.981255Z",
     "iopub.status.busy": "2022-02-03T21:30:37.980893Z",
     "iopub.status.idle": "2022-02-03T21:30:38.234611Z",
     "shell.execute_reply": "2022-02-03T21:30:38.234810Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/used_car_price/data.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-rainbow",
   "metadata": {},
   "source": [
    "We can see a handful of columns above, such as `model, year, price, transmission, mileage, fuelType, tax, mpg, engineSize`. Some columns are numerical whereas others are categorical. We are going to specifically only focus on categorical columns.\n",
    "\n",
    "\n",
    "### 2) Generate JSON-AI Syntax\n",
    "\n",
    "We will make a `LabelEncoder` as follows:\n",
    "\n",
    "(1) Find all unique examples within a column <br>\n",
    "(2) Order the examples in a consistent way <br>\n",
    "(3) Label (python-index of 0 as start) each category <br>\n",
    "(4) Assign the label according to each datapoint. <br>\n",
    "\n",
    "First, let's generate a JSON-AI syntax so we can automatically identify each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-maker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.237433Z",
     "iopub.status.busy": "2022-02-03T21:30:38.237167Z",
     "iopub.status.idle": "2022-02-03T21:30:38.968313Z",
     "shell.execute_reply": "2022-02-03T21:30:38.968531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Problem Definition\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'price', # column you want to predict\n",
    "    #'ignore_features': ['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "})\n",
    "\n",
    "# Generate a JSON-AI object\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-riverside",
   "metadata": {},
   "source": [
    "Let's take a look at our JSON-AI and print to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-paragraph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.972233Z",
     "iopub.status.busy": "2022-02-03T21:30:38.971959Z",
     "iopub.status.idle": "2022-02-03T21:30:38.973971Z",
     "shell.execute_reply": "2022-02-03T21:30:38.973749Z"
    }
   },
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-flour",
   "metadata": {},
   "source": [
    "### 3) Create your custom encoder (`LabelEncoder`).\n",
    "\n",
    "Once our JSON-AI is filled, let's make our LabelEncoder. All Lightwood encoders inherit from the `BaseEncoder` class, found [here](https://github.com/mindsdb/lightwood/blob/staging/lightwood/encoder/base.py). \n",
    "\n",
    "![BaseEncoder](baseencoder.png)\n",
    "\n",
    "\n",
    "The `BaseEncoder` has 5 expected calls:\n",
    "\n",
    "- `__init__`: instantiate the encoder\n",
    "- `prepare`: Train or create the rules of the encoder\n",
    "- `encode`: Given data, convert to the featurized representation\n",
    "- `decode`: Given featurized representations, revert back to data\n",
    "- `to`: Use CPU/GPU (mostly important for learned representations)\n",
    "\n",
    "From above, we see that \"model\", \"transmission\", and \"fuelType\" are all categorical columns. These will be the ones we want to modify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-northwest",
   "metadata": {},
   "source": [
    "##### `LabelEncoder`\n",
    "\n",
    "The `LabelEncoder` should satisfy a couple of rules\n",
    "\n",
    "(1) For the ``__init__`` call: <br>\n",
    "  - Specify the only argument `is_target`; this asks whether the encoder aims to represent the target column.<br>\n",
    "  - Set `is_prepared=False` in the initialization. All encoders are prepared using their `prepare()` call, which turns this flag on to `True` if preparation of the encoders is successful. <br>\n",
    "  - Set `output_size=1`; the output size refers to how many options the represented encoder may adopt. \n",
    "    \n",
    "    \n",
    "(2) For the ``prepare`` call:\n",
    "  - Specify the only argument `priming_data`; this provides the `pd.Series` of the data column for the encoder.\n",
    "  - Find all unique categories in the column data\n",
    "  - Make a dictionary representing label number to category (reserves 0 as Unknown) and the inverse dictionary\n",
    "  - Set `is_prepared=True`\n",
    "  \n",
    "(3) The `encode()` call will convert each data point's category name into the encoded label.\n",
    "\n",
    "(4) The `decode()` call will convert a previously encoded label into the original category name.\n",
    "\n",
    "Given this approach only uses simple dictionaries, there is no need for a dedicated `to()` call (although this would inherit `BaseEncoder`'s implementation).\n",
    "\n",
    "This implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03db1b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.976898Z",
     "iopub.status.busy": "2022-02-03T21:30:38.975171Z",
     "iopub.status.idle": "2022-02-03T21:30:38.978711Z",
     "shell.execute_reply": "2022-02-03T21:30:38.978491Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile LabelEncoder.py\n",
    "\n",
    "\"\"\"\n",
    "2021.10.13\n",
    "\n",
    "Create a LabelEncoder that transforms categorical data into a label.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from lightwood.encoder import BaseEncoder\n",
    "from typing import List, Union\n",
    "from lightwood.helpers.log import log\n",
    "\n",
    "\n",
    "class LabelEncoder(BaseEncoder):\n",
    "    \"\"\"\n",
    "    Create a label representation for categorical data. The data will rely on sorted to organize the order of the labels.\n",
    "\n",
    "    Class Attributes:\n",
    "    - is_target: Whether this is used to encode the target\n",
    "    - is_prepared: Whether the encoder rules have been set (after ``prepare`` is called)\n",
    "\n",
    "    \"\"\"  # noqa\n",
    "\n",
    "    is_target: bool\n",
    "    is_prepared: bool\n",
    "\n",
    "    is_timeseries_encoder: bool = False\n",
    "    is_trainable_encoder: bool = True\n",
    "\n",
    "    def __init__(self, is_target: bool = False, stop_after = 10) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Label Encoder\n",
    "\n",
    "        :param is_target:\n",
    "        \"\"\"\n",
    "        self.is_target = is_target\n",
    "        self.is_prepared = False\n",
    "\n",
    "        # Size of the output encoded dimension per data point\n",
    "        # For LabelEncoder, this is always 1 (1 label per category)\n",
    "        self.output_size = 1\n",
    "\n",
    "    def prepare(self, train_data: pd.Series, dev_data: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Create a LabelEncoder for categorical data.\n",
    "\n",
    "        LabelDict creates a mapping where each index is associated to a category.\n",
    "\n",
    "        :param priming_data: Input column data that is categorical.\n",
    "\n",
    "        :returns: Nothing; prepares encoder rules with `label_dict` and `ilabel_dict`\n",
    "        \"\"\"\n",
    "\n",
    "        # Find all unique categories in the dataset\n",
    "        categories = train_data.unique()\n",
    "\n",
    "        log.info(\"Categories Detected = \" + str(self.output_size))\n",
    "\n",
    "        # Create the Category labeller\n",
    "        self.label_dict = {\"Unknown\": 0}  # Include an unknown category\n",
    "        self.label_dict.update({cat: idx + 1 for idx, cat in enumerate(categories)})\n",
    "        self.ilabel_dict = {idx: cat for cat, idx in self.label_dict.items()}\n",
    "\n",
    "        self.is_prepared = True\n",
    "\n",
    "    def encode(self, column_data: Union[pd.Series, list]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert pre-processed data into the labeled values\n",
    "\n",
    "        :param column_data: Pandas series to convert into labels\n",
    "        \"\"\"\n",
    "        if isinstance(column_data, pd.Series):\n",
    "            enc = column_data.apply(lambda x: self.label_dict.get(x, 0)).tolist()\n",
    "        else:\n",
    "            enc = [self.label_dict.get(x, 0) for x in column_data]\n",
    "\n",
    "        return torch.Tensor(enc).int().unsqueeze(1)\n",
    "\n",
    "    def decode(self, encoded_data: torch.Tensor) -> List[object]:\n",
    "        \"\"\"\n",
    "        Convert torch.Tensor labels into categorical data\n",
    "\n",
    "        :param encoded_data: Encoded data in the form of a torch.Tensor\n",
    "        \"\"\"\n",
    "        return [self.ilabel_dict[i.item()] for i in encoded_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cce8a8",
   "metadata": {},
   "source": [
    "Some additional notes:\n",
    "(1) The `encode()` call should be able to intake a list of values, it is optional to make it compatible with `pd.Series` or `pd.DataFrame` <br>\n",
    "(2) The output of `encode()` must be a torch tensor with dimensionality $N_{rows} x N_{output}$.\n",
    "\n",
    "Now that the `LabelEncoder` is complete, move this to `~/lightwood_modules` and we're ready to try this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30866c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.980727Z",
     "iopub.status.busy": "2022-02-03T21:30:38.980489Z",
     "iopub.status.idle": "2022-02-03T21:30:38.982070Z",
     "shell.execute_reply": "2022-02-03T21:30:38.981851Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightwood import load_custom_module\n",
    "load_custom_module('LabelEncoder.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-archive",
   "metadata": {},
   "source": [
    "### 4) Edit JSON-AI\n",
    "\n",
    "Now that we have our `LabelEncoder` script, we have two ways of introducing this encoder:\n",
    "\n",
    "(1) Change all categorical columns to our encoder of choice <br>\n",
    "(2) Replace the default encoder (`Categorical.OneHotEncoder`) for categorical data to our encoder of choice <br>\n",
    "\n",
    "In the first scenario, we may not want to change ALL columns. By switching the encoder on a `Feature` level, Lightwood allows you to control how representations for a given feature are handled. However, suppose you want to replace an approach entirely with your own methodology - Lightwood supports overriding default methods to control how you want to treat a *data type* as well.\n",
    "\n",
    "Below, we'll show both strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-lodging",
   "metadata": {},
   "source": [
    "The first strategy requires just specifying which features you'd like to change. Once you have your list, you can manually set the encoder \"module\" to the class you'd like. **This is best suited for a few columns or if you only want to override a few particular columns as opposed to replacing the `Encoder` behavior for an entire data type**.\n",
    "#### Strategy 1: Change the encoders for the features directly\n",
    "```python\n",
    "for ft in [\"model\", \"transmission\", \"fuelType\"]: # Features you want to replace\n",
    "    # Set each feature to the custom encoder\n",
    "    json_ai.encoders[ft]['module'] = 'LabelEncoder.LabelEncoder'\n",
    "```\n",
    "\n",
    "\n",
    "Suppose you have many columns that are categorical- you may want to enforce your approach explicitly without naming each column. This can be done by examining the `data_dtype` of JSON-AI's features. For all features that are type `categorical` (while this is a `str`, it's ideal to import dtype and explicitly check the data type), replace the default `Encoder` with your encoder. In this case, this is `LabelEncoder.LabelEncoder`.\n",
    "#### Strategy 2: Programatically change *all* encoder assignments for a data type\n",
    "\n",
    "```python\n",
    "from lightwood.api import dtype\n",
    "for i in json_ai.dtype_dict:\n",
    "    if json_ai.dtype_dict[i] == dtype.categorical:\n",
    "        json_ai.encoders[i]['module'] = 'LabelEncoder.LabelEncoder'\n",
    "```\n",
    "\n",
    "We'll go with the first approach for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-fusion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.983970Z",
     "iopub.status.busy": "2022-02-03T21:30:38.983730Z",
     "iopub.status.idle": "2022-02-03T21:30:38.984867Z",
     "shell.execute_reply": "2022-02-03T21:30:38.985070Z"
    }
   },
   "outputs": [],
   "source": [
    "for ft in [\"model\", \"transmission\", \"fuelType\"]: # Features you want to replace\n",
    "    # Set each feature to the custom encoder\n",
    "    json_ai.encoders[ft]['module'] = 'LabelEncoder.LabelEncoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-austria",
   "metadata": {},
   "source": [
    "### 5) Generate code and your predictor from JSON-AI\n",
    "\n",
    "Now, let's use this JSON-AI object to generate code and make a predictor. This can be done in 2 simple lines, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-james",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.987455Z",
     "iopub.status.busy": "2022-02-03T21:30:38.986031Z",
     "iopub.status.idle": "2022-02-03T21:30:38.993611Z",
     "shell.execute_reply": "2022-02-03T21:30:38.993823Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate python code that fills in your pipeline\n",
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "# Turn the code above into a predictor object\n",
    "predictor = predictor_from_code(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-andorra",
   "metadata": {},
   "source": [
    "Now, let's run our pipeline. To do so, let's first:\n",
    "\n",
    "(1) Perform a statistical analysis on the data (*this is important in preparing Encoders/Mixers as it populates the* `StatisticalAnalysis` *attribute with details some encoders need*). <br>\n",
    "(2) Clean our data <br>\n",
    "(3) Prepare the encoders <br>\n",
    "(4) Featurize the data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-harvey",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:38.996435Z",
     "iopub.status.busy": "2022-02-03T21:30:38.996175Z",
     "iopub.status.idle": "2022-02-03T21:30:39.355344Z",
     "shell.execute_reply": "2022-02-03T21:30:39.355539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform Stats Analysis\n",
    "predictor.analyze_data(df)\n",
    "\n",
    "# Pre-process the data\n",
    "cleaned_data = predictor.preprocess(data=df)\n",
    "\n",
    "# Create a train/test split\n",
    "split_data = predictor.split(cleaned_data)\n",
    "\n",
    "# Prepare the encoders \n",
    "predictor.prepare(split_data)\n",
    "\n",
    "# Featurize the data\n",
    "ft_data = predictor.featurize(split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-beast",
   "metadata": {},
   "source": [
    "The splitter creates 3 data-splits, a \"train\", \"dev\", and \"test\" set. The `featurize` command from the predictor allows us to convert the cleaned data into features. We can access this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-dealing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:39.361308Z",
     "iopub.status.busy": "2022-02-03T21:30:39.361026Z",
     "iopub.status.idle": "2022-02-03T21:30:39.392427Z",
     "shell.execute_reply": "2022-02-03T21:30:39.392125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick a categorical column name\n",
    "col_name = \"fuelType\"\n",
    "\n",
    "# Get the encoded feature data\n",
    "enc_ft = ft_data[\"train\"].get_encoded_column_data(col_name).squeeze(1) #torch tensor (N_rows x N_output_dim)\n",
    "\n",
    "# Get the original data from the dataset\n",
    "orig_data = ft_data[\"train\"].get_column_original_data(col_name) #pandas dataframe\n",
    "\n",
    "# Create a pandas data frame to compare encoded data and original data\n",
    "compare_data = pd.concat([orig_data, pd.Series(enc_ft, name=\"EncData\")], axis=1)\n",
    "compare_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-peoples",
   "metadata": {},
   "source": [
    "We can see what the label mapping is by inspecting our encoders as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-mobility",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T21:30:39.395473Z",
     "iopub.status.busy": "2022-02-03T21:30:39.395212Z",
     "iopub.status.idle": "2022-02-03T21:30:39.396457Z",
     "shell.execute_reply": "2022-02-03T21:30:39.396663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Label Name -> Label Number\n",
    "print(predictor.encoders[col_name].label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-remedy",
   "metadata": {},
   "source": [
    "For each category above, the number associated in the dictionary is the label for each category. This means \"Diesel\" is always represented by a 1, etc.\n",
    "\n",
    "With that, you've created your own custom Encoder that uses a rule-based approach! Please checkout more [tutorials](https://lightwood.io/tutorials.html) for other custom approach guides."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
