<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction &mdash; lightwood 24.5.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                24.5.2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../encoder.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Encoders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mixer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Mixers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Ensemble</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../helpers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Helpers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Introduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/tutorial_update_models/tutorial_update_models.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Introduction">
<h1>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this heading"></a></h1>
<p>In this tutorial, we will go through an example to update a preexisting model. This might be useful when you come across additional data that you would want to consider, without having to train a model from scratch.</p>
<p>The main abstraction that Lightwood offers for this is the <code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code> method. To call it, you need to pass new training data and a held-out dev subset for internal mixer usage (e.g. early stopping). If you are using an aggregate ensemble, it’s likely you will want to do this for every single mixer. The convienient <code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code> does this automatically for you.</p>
</section>
<section id="Initial-model-training">
<h1>Initial model training<a class="headerlink" href="#Initial-model-training" title="Permalink to this heading"></a></h1>
<p>First, let’s train a Lightwood predictor for the <code class="docutils literal notranslate"><span class="pre">concrete</span> <span class="pre">strength</span></code> dataset:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.api.high_level</span> <span class="kn">import</span> <span class="n">ProblemDefinition</span><span class="p">,</span> <span class="n">json_ai_from_problem</span><span class="p">,</span> <span class="n">predictor_from_json_ai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2759:No torchvision detected, image helpers not supported.</span>
<span class="ansi-green-fg">INFO:lightwood-2759:No torchvision/pillow detected, image encoder not supported</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/mindsdb/lightwood/staging/tests/data/concrete_strength.csv&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">update_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train dataframe shape: </span><span class="si">{</span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Update dataframe shape: </span><span class="si">{</span><span class="n">update_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test dataframe shape: </span><span class="si">{</span><span class="n">test_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train dataframe shape: (103, 10)
Update dataframe shape: (721, 10)
Test dataframe shape: (206, 10)
</pre></div></div>
</div>
<p>Note that we have three different data splits.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">training</span></code> split for the initial model training. As you can see, it’s only a 20% of the total data we have. The <code class="docutils literal notranslate"><span class="pre">update</span></code> split will be used as training data to adjust/update our model. Finally, the held out <code class="docutils literal notranslate"><span class="pre">test</span></code> set will give us a rough idea of the impact our updating procedure has on the model’s predictive capabilities.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define predictive task and predictor</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;concrete_strength&#39;</span>
<span class="n">pdef</span> <span class="o">=</span> <span class="n">ProblemDefinition</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="s1">&#39;time_aim&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">})</span>
<span class="n">jai</span> <span class="o">=</span> <span class="n">json_ai_from_problem</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pdef</span><span class="p">)</span>

<span class="c1"># We will keep the architecture simple: a single neural mixer, and a `BestOf` ensemble:</span>
<span class="n">jai</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;BestOf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="s2">&quot;$pred_args&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accuracy_functions&quot;</span><span class="p">:</span> <span class="s2">&quot;$accuracy_functions&quot;</span><span class="p">,</span>
        <span class="s2">&quot;submodels&quot;</span><span class="p">:</span> <span class="p">[{</span>
            <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;Neural&quot;</span><span class="p">,</span>
            <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;fit_on_dev&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;stop_after&quot;</span><span class="p">:</span> <span class="s2">&quot;$problem_definition.seconds_per_mixer&quot;</span><span class="p">,</span>
                <span class="s2">&quot;search_hyperparameters&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">}]</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Build and train the predictor</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_from_json_ai</span><span class="p">(</span><span class="n">jai</span><span class="p">)</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:type_infer-2759:Analyzing a sample of 979</span>
<span class="ansi-green-fg">INFO:type_infer-2759:from a total population of 1030, this is equivalent to 95.0% of your data.</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Using 3 processes to deduct types.</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: cement</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: slag</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column cement has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column slag has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: water</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: flyAsh</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column water has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column flyAsh has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: superPlasticizer</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: coarseAggregate</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column coarseAggregate has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column superPlasticizer has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: fineAggregate</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: age</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column age has data type integer</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: concrete_strength</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column fineAggregate has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column concrete_strength has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Infering type for: id</span>
<span class="ansi-green-fg">INFO:type_infer-2759:Column id has data type integer</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Finished statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 1/8] - Statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Finished statistical analysis</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `analyze_data` runtime: 0.02 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 2/8] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 3/8] - Data splitting</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Splitting the data into train/test</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `split` runtime: 0.0 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 4/8] - Preparing encoders</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing sequentially...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for id...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for cement...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for slag...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for flyAsh...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for water...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for superPlasticizer...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for coarseAggregate...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for fineAggregate...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2759:Preparing encoder for age...</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `prepare` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 5/8] - Feature generation</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `featurize` runtime: 0.06 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 6/8] - Mixer training</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Training the mixers</span>
/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:
        addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
        addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1578.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 39.99637508392334 with learning rate 0.0001</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 21.826460361480713 with learning rate 0.0005</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 15.12899512052536 with learning rate 0.001</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 15.062753021717072 with learning rate 0.002</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 26.490495562553406 with learning rate 0.003</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 33.6572003364563 with learning rate 0.005</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of 303.60721158981323 with learning rate 0.01</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss of nan with learning rate 0.05</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Found learning rate of: 0.002</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 1: 0.11838734149932861</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 2: 0.4641949534416199</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 3: 0.3976145386695862</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 4: 0.3706841468811035</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 5: 0.2367912232875824</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 6: 0.22560915350914001</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 7: 0.12089195847511292</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `fit_mixer` runtime: 0.52 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Ensembling the mixer</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Mixer: Neural got accuracy: 0.238</span>
<span class="ansi-green-fg">INFO:lightwood-2759:Picked best mixer: Neural</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `fit` runtime: 0.53 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 7/8] - Ensemble analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Analyzing the ensemble of mixers</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ICP is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ConfStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block AccStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block PermutationFeatureImportance is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:[PFI] Using a random sample (1000 rows out of 10).</span>
<span class="ansi-green-fg">INFO:lightwood-2759:[PFI] Set to consider first 10 columns out of 9: [&#39;id&#39;, &#39;cement&#39;, &#39;slag&#39;, &#39;flyAsh&#39;, &#39;water&#39;, &#39;superPlasticizer&#39;, &#39;coarseAggregate&#39;, &#39;fineAggregate&#39;, &#39;age&#39;].</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `analyze_ensemble` runtime: 0.15 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Learn phase 8/8] - Adjustment on validation requested</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Updating the mixers</span>
/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 1: 0.1678172747294108</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `adjust` runtime: 0.03 seconds</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `learn` runtime: 0.82 seconds</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train and get predictions for the held out test set</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 1/4] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 2/4] - Feature generation</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `featurize` runtime: 0.03 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 3/4] - Calling ensemble</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `_timed_call` runtime: 0.03 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 4/4] - Analyzing output</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ConfStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block PermutationFeatureImportance is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `explain` runtime: 0.05 seconds</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `predict` runtime: 0.13 seconds</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_index</th>
      <th>prediction</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>40.909630</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>87.398161</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>19.146822</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>65.635353</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>22.482294</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>68.970825</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>19.593765</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>66.082296</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>31.724537</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>78.213068</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>201</td>
      <td>50.553104</td>
      <td>0.9991</td>
      <td>4.064574</td>
      <td>97.041635</td>
    </tr>
    <tr>
      <th>202</th>
      <td>202</td>
      <td>48.580425</td>
      <td>0.9991</td>
      <td>2.091895</td>
      <td>95.068956</td>
    </tr>
    <tr>
      <th>203</th>
      <td>203</td>
      <td>30.114187</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>76.602718</td>
    </tr>
    <tr>
      <th>204</th>
      <td>204</td>
      <td>25.676003</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>72.164533</td>
    </tr>
    <tr>
      <th>205</th>
      <td>205</td>
      <td>41.231636</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>87.720167</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<section id="Updating-the-predictor">
<h2>Updating the predictor<a class="headerlink" href="#Updating-the-predictor" title="Permalink to this heading"></a></h2>
<p>For this, we have two options:</p>
<section id="BaseMixer.partial_fit()">
<h3><code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code><a class="headerlink" href="#BaseMixer.partial_fit()" title="Permalink to this heading"></a></h3>
<p>Updates a single mixer. You need to pass the new data wrapped in <code class="docutils literal notranslate"><span class="pre">EncodedDs</span></code> objects.</p>
<p><strong>Arguments:</strong> * <code class="docutils literal notranslate"><span class="pre">train_data:</span> <span class="pre">EncodedDs</span></code> * <code class="docutils literal notranslate"><span class="pre">dev_data:</span> <span class="pre">EncodedDs</span></code> * <code class="docutils literal notranslate"><span class="pre">adjust_args:</span> <span class="pre">Optional[dict]</span></code> - This will contain any arguments needed by the mixer to adjust new data.</p>
<p>If the mixer does not need a <code class="docutils literal notranslate"><span class="pre">dev_data</span></code> partition, pass a dummy:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>dev_data = EncodedDs(predictor.encoders, pd.DataFrame(), predictor.target)
</pre></div>
</div>
</section>
<section id="PredictorInterface.adjust()">
<h3><code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code><a class="headerlink" href="#PredictorInterface.adjust()" title="Permalink to this heading"></a></h3>
<p>Updates all mixers inside the predictor by calling their respective <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> methods. Any <code class="docutils literal notranslate"><span class="pre">adjust_args</span></code> will be transparently passed as well.</p>
<p><strong>Arguments:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">new_data:</span> <span class="pre">pd.DataFrame</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">old_data:</span> <span class="pre">Optional[pd.DataFrame]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">adjust_args:</span> <span class="pre">Optional[dict]</span></code></p></li>
</ul>
<p>Let’s <code class="docutils literal notranslate"><span class="pre">adjust</span></code> our predictor:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predictor</span><span class="o">.</span><span class="n">adjust</span><span class="p">(</span><span class="n">update_df</span><span class="p">,</span> <span class="n">train_df</span><span class="p">)</span>  <span class="c1"># data to adjust and original data</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `preprocess` runtime: 0.02 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Updating the mixers</span>
/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
<span class="ansi-green-fg">INFO:lightwood-2759:Loss @ epoch 1: 0.10915952424208324</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `adjust` runtime: 0.11 seconds</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">new_predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 1/4] - Data preprocessing</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `preprocess` runtime: 0.01 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 2/4] - Feature generation</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `featurize` runtime: 0.03 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 3/4] - Calling ensemble</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `_timed_call` runtime: 0.03 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2759:[Predict phase 4/4] - Analyzing output</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block ConfStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:ConfStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-green-fg">INFO:lightwood-2759:The block PermutationFeatureImportance is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-2759:PermutationFeatureImportance.explain() has not been implemented, no modifications will be done to the data insights.</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `explain` runtime: 0.05 seconds</span>
<span class="ansi-white-fg">DEBUG:lightwood-2759: `predict` runtime: 0.13 seconds</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>original_index</th>
      <th>prediction</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>43.645542</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>90.134073</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>26.964903</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>73.453434</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>24.151918</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>70.640449</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>20.815800</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>67.304330</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>34.987530</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>81.476060</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>201</td>
      <td>52.630058</td>
      <td>0.9991</td>
      <td>6.141528</td>
      <td>99.118589</td>
    </tr>
    <tr>
      <th>202</th>
      <td>202</td>
      <td>39.175228</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>85.663759</td>
    </tr>
    <tr>
      <th>203</th>
      <td>203</td>
      <td>33.047440</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>79.535970</td>
    </tr>
    <tr>
      <th>204</th>
      <td>204</td>
      <td>28.659138</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>75.147668</td>
    </tr>
    <tr>
      <th>205</th>
      <td>205</td>
      <td>34.264580</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>80.753111</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<p>Nice! Our predictor was updated, and new predictions are looking good. Let’s compare the old and new accuracies to complete the experiment:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">old_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;concrete_strength&#39;</span><span class="p">],</span> <span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>
<span class="n">new_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;concrete_strength&#39;</span><span class="p">],</span> <span class="n">new_predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">old_acc</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">New Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">new_acc</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Old Accuracy: 0.233
New Accuracy: 0.428
</pre></div></div>
</div>
</section>
</section>
<section id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this heading"></a></h2>
<p>We have gone through a simple example of how Lightwood predictors can leverage newly acquired data to improve their predictions. The interface for doing so is fairly simple, requiring only some new data and a single call to update.</p>
<p>You can further customize the logic for updating your mixers by modifying the <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> methods in them.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017-2024, MindsDB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>