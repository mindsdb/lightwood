{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smooth-philip",
   "metadata": {},
   "source": [
    "### Custom Encoder: Rule-Based\n",
    "\n",
    "Lightwood uses \"Encoders\" to convert preprocessed (cleaned) data into **features**. Encoders represent the **feature engineering** step of the data science pipeline; they can either have a set of instructions (\"rule-based\") or a learned representation (trained on data).\n",
    "\n",
    "In the following notebook, we will experiment with creating a custom encoder that creates **Label Encoding**. \n",
    "\n",
    "For example, imagine we have the following set of categories:\n",
    "\n",
    "```\n",
    "MyColumnData = [\"apple\", \"orange\", \"orange\", \"banana\", \"apple\", \"dragonfruit\"]\n",
    "```\n",
    "\n",
    "There are 4 categories to consider: \"apple\", \"banana\", \"orange\", and \"dragonfruit\".\n",
    "\n",
    "**Label encoding** allows you to refer to these categories as if they were numbers. For example, consider the mapping (arranged alphabetically):\n",
    "\n",
    "1 - apple <br>\n",
    "2 - banana <br>\n",
    "3 - dragonfruit <br>\n",
    "4 - orange <br>\n",
    "\n",
    "Using this mapping, we can convert the above data as follows:\n",
    "\n",
    "```\n",
    "MyFeatureData = [1, 4, 4, 2, 1, 3]\n",
    "```\n",
    "\n",
    "In the following notebook, we will design a **LabelEncoder** for Lightwood for use on categorical data. We will be using the Kaggle \"Used Car\" [dataset](https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes). We've provided a link for you to automatically access this CSV. This dataset describes various details of cars on sale - with the goal of predicting how much this car may sell for.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raising-adventure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:16.313933Z",
     "iopub.status.busy": "2022-01-13T23:05:16.313460Z",
     "iopub.status.idle": "2022-01-13T23:05:18.638247Z",
     "shell.execute_reply": "2022-01-13T23:05:18.637737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2140:No torchvision detected, image helpers not supported.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:No torchvision/pillow detected, image encoder not supported\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lightwood modules\n",
    "import lightwood as lw\n",
    "from lightwood import ProblemDefinition, \\\n",
    "                      JsonAI, \\\n",
    "                      json_ai_from_problem, \\\n",
    "                      code_from_json_ai, \\\n",
    "                      predictor_from_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-income",
   "metadata": {},
   "source": [
    "### 1) Load your data\n",
    "\n",
    "Lightwood works with `pandas.DataFrame`s; load data via pandas as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-government",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:18.646509Z",
     "iopub.status.busy": "2022-01-13T23:05:18.646062Z",
     "iopub.status.idle": "2022-01-13T23:05:18.919199Z",
     "shell.execute_reply": "2022-01-13T23:05:18.918794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12500</td>\n",
       "      <td>Manual</td>\n",
       "      <td>15735</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>150</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A6</td>\n",
       "      <td>2016</td>\n",
       "      <td>16500</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>36203</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>20</td>\n",
       "      <td>64.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>2016</td>\n",
       "      <td>11000</td>\n",
       "      <td>Manual</td>\n",
       "      <td>29946</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>30</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>2017</td>\n",
       "      <td>16800</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>25952</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>67.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3</td>\n",
       "      <td>2019</td>\n",
       "      <td>17300</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1998</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>49.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  year  price transmission  mileage fuelType  tax   mpg  engineSize\n",
       "0    A1  2017  12500       Manual    15735   Petrol  150  55.4         1.4\n",
       "1    A6  2016  16500    Automatic    36203   Diesel   20  64.2         2.0\n",
       "2    A1  2016  11000       Manual    29946   Petrol   30  55.4         1.4\n",
       "3    A4  2017  16800    Automatic    25952   Diesel  145  67.3         2.0\n",
       "4    A3  2019  17300       Manual     1998   Petrol  145  49.6         1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/used_car_price/data.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-rainbow",
   "metadata": {},
   "source": [
    "We can see a handful of columns above, such as `model, year, price, transmission, mileage, fuelType, tax, mpg, engineSize`. Some columns are numerical whereas others are categorical. We are going to specifically only focus on categorical columns.\n",
    "\n",
    "\n",
    "### 2) Generate JSON-AI Syntax\n",
    "\n",
    "We will make a `LabelEncoder` as follows:\n",
    "\n",
    "(1) Find all unique examples within a column <br>\n",
    "(2) Order the examples in a consistent way <br>\n",
    "(3) Label (python-index of 0 as start) each category <br>\n",
    "(4) Assign the label according to each datapoint. <br>\n",
    "\n",
    "First, let's generate a JSON-AI syntax so we can automatically identify each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absent-maker",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:18.923562Z",
     "iopub.status.busy": "2022-01-13T23:05:18.922824Z",
     "iopub.status.idle": "2022-01-13T23:05:20.711620Z",
     "shell.execute_reply": "2022-01-13T23:05:20.712288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2140:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Analyzing a sample of 6920\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:from a total population of 10668, this is equivalent to 64.9% of your data.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: model\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column model has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: year\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column year has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: price\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column price has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: transmission\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column transmission has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: mileage\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column mileage has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: fuelType\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column fuelType has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: tax\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column tax has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: mpg\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column mpg has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Infering type for: engineSize\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Column engineSize has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Finished statistical analysis\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the Problem Definition\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'price', # column you want to predict\n",
    "    #'ignore_features': ['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "})\n",
    "\n",
    "# Generate a JSON-AI object\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-riverside",
   "metadata": {},
   "source": [
    "Let's take a look at our JSON-AI and print to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coastal-paragraph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.718536Z",
     "iopub.status.busy": "2022-01-13T23:05:20.717943Z",
     "iopub.status.idle": "2022-01-13T23:05:20.721739Z",
     "shell.execute_reply": "2022-01-13T23:05:20.721355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"features\": {\n",
      "        \"model\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"year\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"transmission\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"mileage\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"fuelType\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"tax\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"mpg\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"float\"\n",
      "        },\n",
      "        \"engineSize\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"float\"\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"price\": {\n",
      "            \"data_dtype\": \"integer\",\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {\n",
      "                    \"is_target\": \"True\",\n",
      "                    \"positive_domain\": \"$statistical_analysis.positive_domain\"\n",
      "                }\n",
      "            },\n",
      "            \"mixers\": [\n",
      "                {\n",
      "                    \"module\": \"Neural\",\n",
      "                    \"args\": {\n",
      "                        \"fit_on_dev\": true,\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\",\n",
      "                        \"search_hyperparameters\": true\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"LightGBM\",\n",
      "                    \"args\": {\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\",\n",
      "                        \"fit_on_dev\": true\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"Regression\",\n",
      "                    \"args\": {\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\"\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"ensemble\": {\n",
      "                \"module\": \"BestOf\",\n",
      "                \"args\": {\n",
      "                    \"args\": \"$pred_args\",\n",
      "                    \"accuracy_functions\": \"$accuracy_functions\",\n",
      "                    \"ts_analysis\": null\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"problem_definition\": {\n",
      "        \"target\": \"price\",\n",
      "        \"pct_invalid\": 2,\n",
      "        \"unbias_target\": true,\n",
      "        \"seconds_per_mixer\": 57024.0,\n",
      "        \"seconds_per_encoder\": null,\n",
      "        \"expected_additional_time\": 1.7800180912017822,\n",
      "        \"time_aim\": 259200,\n",
      "        \"target_weights\": null,\n",
      "        \"positive_domain\": false,\n",
      "        \"timeseries_settings\": {\n",
      "            \"is_timeseries\": false,\n",
      "            \"order_by\": null,\n",
      "            \"window\": null,\n",
      "            \"group_by\": null,\n",
      "            \"use_previous_target\": true,\n",
      "            \"horizon\": null,\n",
      "            \"historical_columns\": null,\n",
      "            \"target_type\": \"\",\n",
      "            \"allow_incomplete_history\": false,\n",
      "            \"eval_cold_start\": true,\n",
      "            \"interval_periods\": []\n",
      "        },\n",
      "        \"anomaly_detection\": false,\n",
      "        \"use_default_analysis\": true,\n",
      "        \"ignore_features\": [],\n",
      "        \"fit_on_all\": true,\n",
      "        \"strict_mode\": true,\n",
      "        \"seed_nr\": 420\n",
      "    },\n",
      "    \"identifiers\": {},\n",
      "    \"accuracy_functions\": [\n",
      "        \"r2_score\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-flour",
   "metadata": {},
   "source": [
    "### 3) Create your custom encoder (`LabelEncoder`).\n",
    "\n",
    "Once our JSON-AI is filled, let's make our LabelEncoder. All Lightwood encoders inherit from the `BaseEncoder` class, found [here](https://github.com/mindsdb/lightwood/blob/staging/lightwood/encoder/base.py). \n",
    "\n",
    "![BaseEncoder](baseencoder.png)\n",
    "\n",
    "\n",
    "The `BaseEncoder` has 5 expected calls:\n",
    "\n",
    "- `__init__`: instantiate the encoder\n",
    "- `prepare`: Train or create the rules of the encoder\n",
    "- `encode`: Given data, convert to the featurized representation\n",
    "- `decode`: Given featurized representations, revert back to data\n",
    "- `to`: Use CPU/GPU (mostly important for learned representations)\n",
    "\n",
    "From above, we see that \"model\", \"transmission\", and \"fuelType\" are all categorical columns. These will be the ones we want to modify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-northwest",
   "metadata": {},
   "source": [
    "##### `LabelEncoder`\n",
    "\n",
    "The `LabelEncoder` should satisfy a couple of rules\n",
    "\n",
    "(1) For the ``__init__`` call: <br>\n",
    "  - Specify the only argument `is_target`; this asks whether the encoder aims to represent the target column.<br>\n",
    "  - Set `is_prepared=False` in the initialization. All encoders are prepared using their `prepare()` call, which turns this flag on to `True` if preparation of the encoders is successful. <br>\n",
    "  - Set `output_size=1`; the output size refers to how many options the represented encoder may adopt. \n",
    "    \n",
    "    \n",
    "(2) For the ``prepare`` call:\n",
    "  - Specify the only argument `priming_data`; this provides the `pd.Series` of the data column for the encoder.\n",
    "  - Find all unique categories in the column data\n",
    "  - Make a dictionary representing label number to category (reserves 0 as Unknown) and the inverse dictionary\n",
    "  - Set `is_prepared=True`\n",
    "  \n",
    "(3) The `encode()` call will convert each data point's category name into the encoded label.\n",
    "\n",
    "(4) The `decode()` call will convert a previously encoded label into the original category name.\n",
    "\n",
    "Given this approach only uses simple dictionaries, there is no need for a dedicated `to()` call (although this would inherit `BaseEncoder`'s implementation).\n",
    "\n",
    "This implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03db1b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.727337Z",
     "iopub.status.busy": "2022-01-13T23:05:20.726578Z",
     "iopub.status.idle": "2022-01-13T23:05:20.730959Z",
     "shell.execute_reply": "2022-01-13T23:05:20.730578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing LabelEncoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile LabelEncoder.py\n",
    "\n",
    "\"\"\"\n",
    "2021.10.13\n",
    "\n",
    "Create a LabelEncoder that transforms categorical data into a label.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from lightwood.encoder import BaseEncoder\n",
    "from typing import List, Union\n",
    "from lightwood.helpers.log import log\n",
    "\n",
    "\n",
    "class LabelEncoder(BaseEncoder):\n",
    "    \"\"\"\n",
    "    Create a label representation for categorical data. The data will rely on sorted to organize the order of the labels.\n",
    "\n",
    "    Class Attributes:\n",
    "    - is_target: Whether this is used to encode the target\n",
    "    - is_prepared: Whether the encoder rules have been set (after ``prepare`` is called)\n",
    "\n",
    "    \"\"\"  # noqa\n",
    "\n",
    "    is_target: bool\n",
    "    is_prepared: bool\n",
    "\n",
    "    is_timeseries_encoder: bool = False\n",
    "    is_trainable_encoder: bool = False\n",
    "\n",
    "    def __init__(self, is_target: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Label Encoder\n",
    "\n",
    "        :param is_target:\n",
    "        \"\"\"\n",
    "        self.is_target = is_target\n",
    "        self.is_prepared = False\n",
    "\n",
    "        # Size of the output encoded dimension per data point\n",
    "        # For LabelEncoder, this is always 1 (1 label per category)\n",
    "        self.output_size = 1\n",
    "\n",
    "    # Not all encoders need to be prepared\n",
    "    def prepare(self, priming_data: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Create a LabelEncoder for categorical data.\n",
    "\n",
    "        LabelDict creates a mapping where each index is associated to a category.\n",
    "\n",
    "        :param priming_data: Input column data that is categorical.\n",
    "\n",
    "        :returns: Nothing; prepares encoder rules with `label_dict` and `ilabel_dict`\n",
    "        \"\"\"\n",
    "\n",
    "        # Find all unique categories in the dataset\n",
    "        categories = priming_data.unique()\n",
    "\n",
    "        log.info(\"Categories Detected = \" + str(self.output_size))\n",
    "\n",
    "        # Create the Category labeller\n",
    "        self.label_dict = {\"Unknown\": 0}  # Include an unknown category\n",
    "        self.label_dict.update({cat: idx + 1 for idx, cat in enumerate(categories)})\n",
    "        self.ilabel_dict = {idx: cat for cat, idx in self.label_dict.items()}\n",
    "\n",
    "        self.is_prepared = True\n",
    "\n",
    "    def encode(self, column_data: Union[pd.Series, list]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convert pre-processed data into the labeled values\n",
    "\n",
    "        :param column_data: Pandas series to convert into labels\n",
    "        \"\"\"\n",
    "        if isinstance(column_data, pd.Series):\n",
    "            enc = column_data.apply(lambda x: self.label_dict.get(x, 0)).tolist()\n",
    "        else:\n",
    "            enc = [self.label_dict.get(x, 0) for x in column_data]\n",
    "\n",
    "        return torch.Tensor(enc).int().unsqueeze(1)\n",
    "\n",
    "    def decode(self, encoded_data: torch.Tensor) -> List[object]:\n",
    "        \"\"\"\n",
    "        Convert torch.Tensor labels into categorical data\n",
    "\n",
    "        :param encoded_data: Encoded data in the form of a torch.Tensor\n",
    "        \"\"\"\n",
    "        return [self.ilabel_dict[i.item()] for i in encoded_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cce8a8",
   "metadata": {},
   "source": [
    "Some additional notes:\n",
    "(1) The `encode()` call should be able to intake a list of values, it is optional to make it compatible with `pd.Series` or `pd.DataFrame` <br>\n",
    "(2) The output of `encode()` must be a torch tensor with dimensionality $N_{rows} x N_{output}$.\n",
    "\n",
    "Now that the `LabelEncoder` is complete, move this to `~/lightwood_modules` and we're ready to try this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30866c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.734680Z",
     "iopub.status.busy": "2022-01-13T23:05:20.733869Z",
     "iopub.status.idle": "2022-01-13T23:05:20.737173Z",
     "shell.execute_reply": "2022-01-13T23:05:20.736783Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightwood import load_custom_module\n",
    "load_custom_module('LabelEncoder.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-archive",
   "metadata": {},
   "source": [
    "### 4) Edit JSON-AI\n",
    "\n",
    "Now that we have our `LabelEncoder` script, we have two ways of introducing this encoder:\n",
    "\n",
    "(1) Change all categorical columns to our encoder of choice <br>\n",
    "(2) Replace the default encoder (`Categorical.OneHotEncoder`) for categorical data to our encoder of choice <br>\n",
    "\n",
    "In the first scenario, we may not want to change ALL columns. By switching the encoder on a `Feature` level, Lightwood allows you to control how representations for a given feature are handled. However, suppose you want to replace an approach entirely with your own methodology - Lightwood supports overriding default methods to control how you want to treat a *data type* as well.\n",
    "\n",
    "Below, we'll show both strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-lodging",
   "metadata": {},
   "source": [
    "The first strategy requires just specifying which features you'd like to change. Once you have your list, you can manually set the encoder \"module\" to the class you'd like. **This is best suited for a few columns or if you only want to override a few particular columns as opposed to replacing the `Encoder` behavior for an entire data type**.\n",
    "#### Strategy 1: Change the encoders for the features directly\n",
    "```python\n",
    "for ft in [\"model\", \"transmission\", \"fuelType\"]: # Features you want to replace\n",
    "    # Set each feature to the custom encoder\n",
    "    json_ai.features[ft].encoder['module'] = 'LabelEncoder.LabelEncoder'\n",
    "```\n",
    "\n",
    "\n",
    "Suppose you have many columns that are categorical- you may want to enforce your approach explicitly without naming each column. This can be done by examining the `data_dtype` of JSON-AI's features. For all features that are type `categorical` (while this is a `str`, it's ideal to import dtype and explicitly check the data type), replace the default `Encoder` with your encoder. In this case, this is `LabelEncoder.LabelEncoder`.\n",
    "#### Strategy 2: Programatically change *all* encoder assignments for a data type\n",
    "\n",
    "```python\n",
    "from lightwood.api import dtype\n",
    "for i in json_ai.features:\n",
    "    if json_ai.features[i].data_dtype == dtype.categorical:\n",
    "        json_ai.features[i].encoder['module'] = 'LabelEncoder.LabelEncoder'\n",
    "```\n",
    "\n",
    "We'll go with the first approach for simplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elementary-fusion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.741064Z",
     "iopub.status.busy": "2022-01-13T23:05:20.739169Z",
     "iopub.status.idle": "2022-01-13T23:05:20.743523Z",
     "shell.execute_reply": "2022-01-13T23:05:20.743144Z"
    }
   },
   "outputs": [],
   "source": [
    "for ft in [\"model\", \"transmission\", \"fuelType\"]: # Features you want to replace\n",
    "    # Set each feature to the custom encoder\n",
    "    json_ai.features[ft].encoder['module'] = 'LabelEncoder.LabelEncoder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-austria",
   "metadata": {},
   "source": [
    "### 5) Generate code and your predictor from JSON-AI\n",
    "\n",
    "Now, let's use this JSON-AI object to generate code and make a predictor. This can be done in 2 simple lines, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inappropriate-james",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.747845Z",
     "iopub.status.busy": "2022-01-13T23:05:20.746999Z",
     "iopub.status.idle": "2022-01-13T23:05:20.980980Z",
     "shell.execute_reply": "2022-01-13T23:05:20.980542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2140:Unable to import black formatter, predictor code might be a bit ugly.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Generate python code that fills in your pipeline\n",
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "# Turn the code above into a predictor object\n",
    "predictor = predictor_from_code(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-andorra",
   "metadata": {},
   "source": [
    "Now, let's run our pipeline. To do so, let's first:\n",
    "\n",
    "(1) Perform a statistical analysis on the data (*this is important in preparing Encoders/Mixers as it populates the* `StatisticalAnalysis` *attribute with details some encoders need*). <br>\n",
    "(2) Clean our data <br>\n",
    "(3) Prepare the encoders <br>\n",
    "(4) Featurize the data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "palestinian-harvey",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:20.985122Z",
     "iopub.status.busy": "2022-01-13T23:05:20.984677Z",
     "iopub.status.idle": "2022-01-13T23:05:21.659507Z",
     "shell.execute_reply": "2022-01-13T23:05:21.659127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2140:Performing statistical analysis on data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Finished statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Cleaning the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Splitting the data into train/test\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Preparing the encoders\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 2\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 3\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 4\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 5\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 6\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 7\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 8\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Encoder prepping dict length of: 9\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: price\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Categories Detected = 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: model\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: year\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Categories Detected = 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: transmission\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: mileage\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Categories Detected = 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: fuelType\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: tax\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: mpg\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Done running for: engineSize\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2140:Featurizing the data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Perform Stats Analysis\n",
    "predictor.analyze_data(df)\n",
    "\n",
    "# Pre-process the data\n",
    "cleaned_data = predictor.preprocess(data=df)\n",
    "\n",
    "# Create a train/test split\n",
    "split_data = predictor.split(cleaned_data)\n",
    "\n",
    "# Prepare the encoders \n",
    "predictor.prepare(split_data)\n",
    "\n",
    "# Featurize the data\n",
    "ft_data = predictor.featurize(split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-beast",
   "metadata": {},
   "source": [
    "The splitter creates 3 data-splits, a \"train\", \"dev\", and \"test\" set. The `featurize` command from the predictor allows us to convert the cleaned data into features. We can access this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silent-dealing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:21.665135Z",
     "iopub.status.busy": "2022-01-13T23:05:21.664666Z",
     "iopub.status.idle": "2022-01-13T23:05:21.677192Z",
     "shell.execute_reply": "2022-01-13T23:05:21.676414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuelType</th>\n",
       "      <th>EncData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petrol</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fuelType  EncData\n",
       "0   Diesel        1\n",
       "1   Diesel        1\n",
       "2   Diesel        1\n",
       "3   Petrol        2\n",
       "4   Diesel        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a categorical column name\n",
    "col_name = \"fuelType\"\n",
    "\n",
    "# Get the encoded feature data\n",
    "enc_ft = ft_data[\"train\"].get_encoded_column_data(col_name).squeeze(1) #torch tensor (N_rows x N_output_dim)\n",
    "\n",
    "# Get the original data from the dataset\n",
    "orig_data = ft_data[\"train\"].get_column_original_data(col_name) #pandas dataframe\n",
    "\n",
    "# Create a pandas data frame to compare encoded data and original data\n",
    "compare_data = pd.concat([orig_data, pd.Series(enc_ft, name=\"EncData\")], axis=1)\n",
    "compare_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-peoples",
   "metadata": {},
   "source": [
    "We can see what the label mapping is by inspecting our encoders as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "superior-mobility",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T23:05:21.680678Z",
     "iopub.status.busy": "2022-01-13T23:05:21.680200Z",
     "iopub.status.idle": "2022-01-13T23:05:21.683702Z",
     "shell.execute_reply": "2022-01-13T23:05:21.683327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unknown': 0, 'Diesel': 1, 'Petrol': 2, 'Hybrid': 3}\n"
     ]
    }
   ],
   "source": [
    "# Label Name -> Label Number\n",
    "print(predictor.encoders[col_name].label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-remedy",
   "metadata": {},
   "source": [
    "For each category above, the number associated in the dictionary is the label for each category. This means \"Diesel\" is always represented by a 1, etc.\n",
    "\n",
    "With that, you've created your own custom Encoder that uses a rule-based approach! Please checkout more [tutorials](https://lightwood.io/tutorials.html) for other custom approach guides."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
