

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Custom Encoder: Rule-Based &mdash; lightwood 24.5.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />

  
      <script src="../../_static/jquery.js"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
      <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
      <script src="../../_static/doctools.js"></script>
      <script src="../../_static/sphinx_highlight.js"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../encoder.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Encoders</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mixer.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Mixers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Ensemble</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../helpers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Helpers</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Custom Encoder: Rule-Based</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/custom_encoder_rulebased/custom_encoder_rulebased.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Custom-Encoder:-Rule-Based">
<h1>Custom Encoder: Rule-Based<a class="headerlink" href="#Custom-Encoder:-Rule-Based" title="Permalink to this heading"></a></h1>
<p>Lightwood uses “Encoders” to convert preprocessed (cleaned) data into <strong>features</strong>. Encoders represent the <strong>feature engineering</strong> step of the data science pipeline; they can either have a set of instructions (“rule-based”) or a learned representation (trained on data).</p>
<p>In the following notebook, we will experiment with creating a custom encoder that creates <strong>Label Encoding</strong>.</p>
<p>For example, imagine we have the following set of categories:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>MyColumnData = [&quot;apple&quot;, &quot;orange&quot;, &quot;orange&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;dragonfruit&quot;]
</pre></div>
</div>
<p>There are 4 categories to consider: “apple”, “banana”, “orange”, and “dragonfruit”.</p>
<p><strong>Label encoding</strong> allows you to refer to these categories as if they were numbers. For example, consider the mapping (arranged alphabetically):</p>
<p>1 - apple 2 - banana 3 - dragonfruit 4 - orange</p>
<p>Using this mapping, we can convert the above data as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>MyFeatureData = [1, 4, 4, 2, 1, 3]
</pre></div>
</div>
<p>In the following notebook, we will design a <strong>LabelEncoder</strong> for Lightwood for use on categorical data. We will be using the Kaggle “Used Car” <a class="reference external" href="https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes">dataset</a>. We’ve provided a link for you to automatically access this CSV. This dataset describes various details of cars on sale - with the goal of predicting how much this car may sell for.</p>
<p>Let’s get started.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Lightwood modules</span>
<span class="kn">import</span> <span class="nn">lightwood</span> <span class="k">as</span> <span class="nn">lw</span>
<span class="kn">from</span> <span class="nn">lightwood</span> <span class="kn">import</span> <span class="n">ProblemDefinition</span><span class="p">,</span> \
                      <span class="n">JsonAI</span><span class="p">,</span> \
                      <span class="n">json_ai_from_problem</span><span class="p">,</span> \
                      <span class="n">code_from_json_ai</span><span class="p">,</span> \
                      <span class="n">predictor_from_code</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-2459:No torchvision detected, image helpers not supported.</span>
<span class="ansi-green-fg">INFO:lightwood-2459:No torchvision/pillow detected, image encoder not supported</span>
</pre></div></div>
</div>
</section>
<section id="1)-Load-your-data">
<h1>1) Load your data<a class="headerlink" href="#1)-Load-your-data" title="Permalink to this heading"></a></h1>
<p>Lightwood works with <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code>s; load data via pandas as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/used_car_price/data.csv&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>year</th>
      <th>price</th>
      <th>transmission</th>
      <th>mileage</th>
      <th>fuelType</th>
      <th>tax</th>
      <th>mpg</th>
      <th>engineSize</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A1</td>
      <td>2017</td>
      <td>12500</td>
      <td>Manual</td>
      <td>15735</td>
      <td>Petrol</td>
      <td>150</td>
      <td>55.4</td>
      <td>1.4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A6</td>
      <td>2016</td>
      <td>16500</td>
      <td>Automatic</td>
      <td>36203</td>
      <td>Diesel</td>
      <td>20</td>
      <td>64.2</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A1</td>
      <td>2016</td>
      <td>11000</td>
      <td>Manual</td>
      <td>29946</td>
      <td>Petrol</td>
      <td>30</td>
      <td>55.4</td>
      <td>1.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A4</td>
      <td>2017</td>
      <td>16800</td>
      <td>Automatic</td>
      <td>25952</td>
      <td>Diesel</td>
      <td>145</td>
      <td>67.3</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A3</td>
      <td>2019</td>
      <td>17300</td>
      <td>Manual</td>
      <td>1998</td>
      <td>Petrol</td>
      <td>145</td>
      <td>49.6</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can see a handful of columns above, such as <code class="docutils literal notranslate"><span class="pre">model,</span> <span class="pre">year,</span> <span class="pre">price,</span> <span class="pre">transmission,</span> <span class="pre">mileage,</span> <span class="pre">fuelType,</span> <span class="pre">tax,</span> <span class="pre">mpg,</span> <span class="pre">engineSize</span></code>. Some columns are numerical whereas others are categorical. We are going to specifically only focus on categorical columns.</p>
</section>
<section id="2)-Generate-JSON-AI-Syntax">
<h1>2) Generate JSON-AI Syntax<a class="headerlink" href="#2)-Generate-JSON-AI-Syntax" title="Permalink to this heading"></a></h1>
<p>We will make a <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> as follows:</p>
<ol class="arabic simple">
<li><p>Find all unique examples within a column</p></li>
<li><p>Order the examples in a consistent way</p></li>
<li><p>Label (python-index of 0 as start) each category</p></li>
<li><p>Assign the label according to each datapoint.</p></li>
</ol>
<p>First, let’s generate a JSON-AI syntax so we can automatically identify each column.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the Problem Definition</span>
<span class="n">pdef</span> <span class="o">=</span> <span class="n">ProblemDefinition</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
    <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="s1">&#39;price&#39;</span><span class="p">,</span> <span class="c1"># column you want to predict</span>
    <span class="c1">#&#39;ignore_features&#39;: [&#39;year&#39;, &#39;mileage&#39;, &#39;tax&#39;, &#39;mpg&#39;, &#39;engineSize&#39;]</span>
<span class="p">})</span>

<span class="c1"># Generate a JSON-AI object</span>
<span class="n">json_ai</span> <span class="o">=</span> <span class="n">json_ai_from_problem</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">problem_definition</span><span class="o">=</span><span class="n">pdef</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:type_infer-2459:Analyzing a sample of 6920</span>
<span class="ansi-green-fg">INFO:type_infer-2459:from a total population of 10668, this is equivalent to 64.9% of your data.</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Using 3 processes to deduct types.</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: year</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: price</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column year has data type integer</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column price has data type integer</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: transmission</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: mileage</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column mileage has data type integer</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: model</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: fuelType</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column transmission has data type categorical</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: tax</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column tax has data type integer</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: mpg</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column mpg has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Infering type for: engineSize</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column engineSize has data type float</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column fuelType has data type categorical</span>
<span class="ansi-green-fg">INFO:type_infer-2459:Column model has data type categorical</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Finished statistical analysis</span>
</pre></div></div>
</div>
<p>Let’s take a look at our JSON-AI and print to file.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">json_ai</span><span class="o">.</span><span class="n">to_json</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{
    &#34;encoders&#34;: {
        &#34;price&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {
                &#34;is_target&#34;: &#34;True&#34;,
                &#34;positive_domain&#34;: &#34;$statistical_analysis.positive_domain&#34;
            }
        },
        &#34;model&#34;: {
            &#34;module&#34;: &#34;CategoricalAutoEncoder&#34;,
            &#34;args&#34;: {
                &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_encoder&#34;
            }
        },
        &#34;year&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;transmission&#34;: {
            &#34;module&#34;: &#34;OneHotEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;mileage&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;fuelType&#34;: {
            &#34;module&#34;: &#34;OneHotEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;tax&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;mpg&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {}
        },
        &#34;engineSize&#34;: {
            &#34;module&#34;: &#34;NumericEncoder&#34;,
            &#34;args&#34;: {}
        }
    },
    &#34;dtype_dict&#34;: {
        &#34;model&#34;: &#34;categorical&#34;,
        &#34;year&#34;: &#34;integer&#34;,
        &#34;price&#34;: &#34;integer&#34;,
        &#34;transmission&#34;: &#34;categorical&#34;,
        &#34;mileage&#34;: &#34;integer&#34;,
        &#34;fuelType&#34;: &#34;categorical&#34;,
        &#34;tax&#34;: &#34;integer&#34;,
        &#34;mpg&#34;: &#34;float&#34;,
        &#34;engineSize&#34;: &#34;float&#34;
    },
    &#34;dependency_dict&#34;: {},
    &#34;model&#34;: {
        &#34;module&#34;: &#34;BestOf&#34;,
        &#34;args&#34;: {
            &#34;submodels&#34;: [
                {
                    &#34;module&#34;: &#34;Neural&#34;,
                    &#34;args&#34;: {
                        &#34;fit_on_dev&#34;: true,
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;search_hyperparameters&#34;: true
                    }
                },
                {
                    &#34;module&#34;: &#34;XGBoostMixer&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;fit_on_dev&#34;: true
                    }
                },
                {
                    &#34;module&#34;: &#34;Regression&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;
                    }
                },
                {
                    &#34;module&#34;: &#34;RandomForest&#34;,
                    &#34;args&#34;: {
                        &#34;stop_after&#34;: &#34;$problem_definition.seconds_per_mixer&#34;,
                        &#34;fit_on_dev&#34;: true
                    }
                }
            ]
        }
    },
    &#34;problem_definition&#34;: {
        &#34;target&#34;: &#34;price&#34;,
        &#34;pct_invalid&#34;: 2,
        &#34;unbias_target&#34;: true,
        &#34;seconds_per_mixer&#34;: 21384.0,
        &#34;seconds_per_encoder&#34;: 85536.0,
        &#34;expected_additional_time&#34;: 11.133111953735352,
        &#34;time_aim&#34;: 259200,
        &#34;target_weights&#34;: null,
        &#34;positive_domain&#34;: false,
        &#34;timeseries_settings&#34;: {
            &#34;is_timeseries&#34;: false,
            &#34;order_by&#34;: null,
            &#34;window&#34;: null,
            &#34;group_by&#34;: null,
            &#34;use_previous_target&#34;: true,
            &#34;horizon&#34;: null,
            &#34;historical_columns&#34;: null,
            &#34;target_type&#34;: &#34;&#34;,
            &#34;allow_incomplete_history&#34;: true,
            &#34;eval_incomplete&#34;: false,
            &#34;interval_periods&#34;: []
        },
        &#34;anomaly_detection&#34;: false,
        &#34;use_default_analysis&#34;: true,
        &#34;embedding_only&#34;: false,
        &#34;dtype_dict&#34;: {},
        &#34;ignore_features&#34;: [],
        &#34;fit_on_all&#34;: true,
        &#34;strict_mode&#34;: true,
        &#34;seed_nr&#34;: 1
    },
    &#34;identifiers&#34;: {},
    &#34;imputers&#34;: [],
    &#34;accuracy_functions&#34;: [
        &#34;r2_score&#34;
    ]
}
</pre></div></div>
</div>
</section>
<section id="3)-Create-your-custom-encoder-(LabelEncoder).">
<h1>3) Create your custom encoder (<code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code>).<a class="headerlink" href="#3)-Create-your-custom-encoder-(LabelEncoder)." title="Permalink to this heading"></a></h1>
<p>Once our JSON-AI is filled, let’s make our LabelEncoder. All Lightwood encoders inherit from the <code class="docutils literal notranslate"><span class="pre">BaseEncoder</span></code> class, found <a class="reference external" href="https://github.com/mindsdb/lightwood/blob/staging/lightwood/encoder/base.py">here</a>.</p>
<p><img alt="BaseEncoder" src="../../_images/baseencoder.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">BaseEncoder</span></code> has 5 expected calls:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>: instantiate the encoder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prepare</span></code>: Train or create the rules of the encoder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">encode</span></code>: Given data, convert to the featurized representation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">decode</span></code>: Given featurized representations, revert back to data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">to</span></code>: Use CPU/GPU (mostly important for learned representations)</p></li>
</ul>
<p>From above, we see that “model”, “transmission”, and “fuelType” are all categorical columns. These will be the ones we want to modify.</p>
<section id="LabelEncoder">
<h2><code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code><a class="headerlink" href="#LabelEncoder" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> should satisfy a couple of rules</p>
<ol class="arabic simple">
<li><p>For the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> call:</p></li>
</ol>
<ul class="simple">
<li><p>Specify the only argument <code class="docutils literal notranslate"><span class="pre">is_target</span></code>; this asks whether the encoder aims to represent the target column.</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">is_prepared=False</span></code> in the initialization. All encoders are prepared using their <code class="docutils literal notranslate"><span class="pre">prepare()</span></code> call, which turns this flag on to <code class="docutils literal notranslate"><span class="pre">True</span></code> if preparation of the encoders is successful.</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">output_size=1</span></code>; the output size refers to how many options the represented encoder may adopt.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>For the <code class="docutils literal notranslate"><span class="pre">prepare</span></code> call:</p></li>
</ol>
<ul class="simple">
<li><p>Specify the only argument <code class="docutils literal notranslate"><span class="pre">priming_data</span></code>; this provides the <code class="docutils literal notranslate"><span class="pre">pd.Series</span></code> of the data column for the encoder.</p></li>
<li><p>Find all unique categories in the column data</p></li>
<li><p>Make a dictionary representing label number to category (reserves 0 as Unknown) and the inverse dictionary</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">is_prepared=True</span></code></p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>The <code class="docutils literal notranslate"><span class="pre">encode()</span></code> call will convert each data point’s category name into the encoded label.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">decode()</span></code> call will convert a previously encoded label into the original category name.</p></li>
</ol>
<p>Given this approach only uses simple dictionaries, there is no need for a dedicated <code class="docutils literal notranslate"><span class="pre">to()</span></code> call (although this would inherit <code class="docutils literal notranslate"><span class="pre">BaseEncoder</span></code>’s implementation).</p>
<p>This implementation would look as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> LabelEncoder.py

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">2021.10.13</span>

<span class="sd">Create a LabelEncoder that transforms categorical data into a label.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">lightwood.encoder</span> <span class="kn">import</span> <span class="n">BaseEncoder</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">lightwood.helpers.log</span> <span class="kn">import</span> <span class="n">log</span>


<span class="k">class</span> <span class="nc">LabelEncoder</span><span class="p">(</span><span class="n">BaseEncoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a label representation for categorical data. The data will rely on sorted to organize the order of the labels.</span>

<span class="sd">    Class Attributes:</span>
<span class="sd">    - is_target: Whether this is used to encode the target</span>
<span class="sd">    - is_prepared: Whether the encoder rules have been set (after ``prepare`` is called)</span>

<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa</span>

    <span class="n">is_target</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">is_prepared</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="n">is_timeseries_encoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">is_trainable_encoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_target</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">stop_after</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Label Encoder</span>

<span class="sd">        :param is_target:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_target</span> <span class="o">=</span> <span class="n">is_target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_prepared</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Size of the output encoded dimension per data point</span>
        <span class="c1"># For LabelEncoder, this is always 1 (1 label per category)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">dev_data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a LabelEncoder for categorical data.</span>

<span class="sd">        LabelDict creates a mapping where each index is associated to a category.</span>

<span class="sd">        :param priming_data: Input column data that is categorical.</span>

<span class="sd">        :returns: Nothing; prepares encoder rules with `label_dict` and `ilabel_dict`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Find all unique categories in the dataset</span>
        <span class="n">categories</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Categories Detected = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># Create the Category labeller</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Unknown&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>  <span class="c1"># Include an unknown category</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">cat</span><span class="p">:</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">cat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">categories</span><span class="p">)})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ilabel_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">cat</span> <span class="k">for</span> <span class="n">cat</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_prepared</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column_data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert pre-processed data into the labeled values</span>

<span class="sd">        :param column_data: Pandas series to convert into labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="n">enc</span> <span class="o">=</span> <span class="n">column_data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">enc</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">column_data</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">enc</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">object</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert torch.Tensor labels into categorical data</span>

<span class="sd">        :param encoded_data: Encoded data in the form of a torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">ilabel_dict</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">encoded_data</span><span class="p">]</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing LabelEncoder.py
</pre></div></div>
</div>
<p>Some additional notes: (1) The <code class="docutils literal notranslate"><span class="pre">encode()</span></code> call should be able to intake a list of values, it is optional to make it compatible with <code class="docutils literal notranslate"><span class="pre">pd.Series</span></code> or <code class="docutils literal notranslate"><span class="pre">pd.DataFrame</span></code> (2) The output of <code class="docutils literal notranslate"><span class="pre">encode()</span></code> must be a torch tensor with dimensionality <span class="math notranslate nohighlight">\(N_{rows} x N_{output}\)</span>.</p>
<p>Now that the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> is complete, move this to <code class="docutils literal notranslate"><span class="pre">~/lightwood_modules</span></code> and we’re ready to try this out!</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood</span> <span class="kn">import</span> <span class="n">load_custom_module</span>
<span class="n">load_custom_module</span><span class="p">(</span><span class="s1">&#39;LabelEncoder.py&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="4)-Edit-JSON-AI">
<h1>4) Edit JSON-AI<a class="headerlink" href="#4)-Edit-JSON-AI" title="Permalink to this heading"></a></h1>
<p>Now that we have our <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> script, we have two ways of introducing this encoder:</p>
<ol class="arabic simple">
<li><p>Change all categorical columns to our encoder of choice</p></li>
<li><p>Replace the default encoder (<code class="docutils literal notranslate"><span class="pre">Categorical.OneHotEncoder</span></code>) for categorical data to our encoder of choice</p></li>
</ol>
<p>In the first scenario, we may not want to change ALL columns. By switching the encoder on a <code class="docutils literal notranslate"><span class="pre">Feature</span></code> level, Lightwood allows you to control how representations for a given feature are handled. However, suppose you want to replace an approach entirely with your own methodology - Lightwood supports overriding default methods to control how you want to treat a <em>data type</em> as well.</p>
<p>Below, we’ll show both strategies:</p>
<p>The first strategy requires just specifying which features you’d like to change. Once you have your list, you can manually set the encoder “module” to the class you’d like. <strong>This is best suited for a few columns or if you only want to override a few particular columns as opposed to replacing the ``Encoder`` behavior for an entire data type</strong>. #### Strategy 1: Change the encoders for the features directly</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">ft</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;transmission&quot;</span><span class="p">,</span> <span class="s2">&quot;fuelType&quot;</span><span class="p">]:</span> <span class="c1"># Features you want to replace</span>
    <span class="c1"># Set each feature to the custom encoder</span>
    <span class="n">json_ai</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">ft</span><span class="p">][</span><span class="s1">&#39;module&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;LabelEncoder.LabelEncoder&#39;</span>
</pre></div>
</div>
<p>Suppose you have many columns that are categorical- you may want to enforce your approach explicitly without naming each column. This can be done by examining the <code class="docutils literal notranslate"><span class="pre">data_dtype</span></code> of JSON-AI’s features. For all features that are type <code class="docutils literal notranslate"><span class="pre">categorical</span></code> (while this is a <code class="docutils literal notranslate"><span class="pre">str</span></code>, it’s ideal to import dtype and explicitly check the data type), replace the default <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> with your encoder. In this case, this is <code class="docutils literal notranslate"><span class="pre">LabelEncoder.LabelEncoder</span></code>. #### Strategy 2: Programatically change <em>all</em> encoder
assignments for a data type</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightwood.api</span> <span class="kn">import</span> <span class="n">dtype</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">json_ai</span><span class="o">.</span><span class="n">dtype_dict</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">json_ai</span><span class="o">.</span><span class="n">dtype_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">dtype</span><span class="o">.</span><span class="n">categorical</span><span class="p">:</span>
        <span class="n">json_ai</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;module&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;LabelEncoder.LabelEncoder&#39;</span>
</pre></div>
</div>
<p>We’ll go with the first approach for simplicity:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">ft</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;transmission&quot;</span><span class="p">,</span> <span class="s2">&quot;fuelType&quot;</span><span class="p">]:</span> <span class="c1"># Features you want to replace</span>
    <span class="c1"># Set each feature to the custom encoder</span>
    <span class="n">json_ai</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">ft</span><span class="p">][</span><span class="s1">&#39;module&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;LabelEncoder.LabelEncoder&#39;</span>
</pre></div>
</div>
</div>
</section>
<section id="5)-Generate-code-and-your-predictor-from-JSON-AI">
<h1>5) Generate code and your predictor from JSON-AI<a class="headerlink" href="#5)-Generate-code-and-your-predictor-from-JSON-AI" title="Permalink to this heading"></a></h1>
<p>Now, let’s use this JSON-AI object to generate code and make a predictor. This can be done in 2 simple lines, below:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Generate python code that fills in your pipeline</span>
<span class="n">code</span> <span class="o">=</span> <span class="n">code_from_json_ai</span><span class="p">(</span><span class="n">json_ai</span><span class="p">)</span>

<span class="c1"># Turn the code above into a predictor object</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_from_code</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now, let’s run our pipeline. To do so, let’s first:</p>
<ol class="arabic simple">
<li><p>Perform a statistical analysis on the data (<em>this is important in preparing Encoders/Mixers as it populates the</em> <code class="docutils literal notranslate"><span class="pre">StatisticalAnalysis</span></code> <em>attribute with details some encoders need</em>).</p></li>
<li><p>Clean our data</p></li>
<li><p>Prepare the encoders</p></li>
<li><p>Featurize the data</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform Stats Analysis</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">analyze_data</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Pre-process the data</span>
<span class="n">cleaned_data</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Create a train/test split</span>
<span class="n">split_data</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">cleaned_data</span><span class="p">)</span>

<span class="c1"># Prepare the encoders</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">split_data</span><span class="p">)</span>

<span class="c1"># Featurize the data</span>
<span class="n">ft_data</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">featurize</span><span class="p">(</span><span class="n">split_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Finished statistical analysis</span>
<span class="ansi-white-fg">DEBUG:lightwood-2459: `analyze_data` runtime: 0.43 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Cleaning the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2459: `preprocess` runtime: 0.13 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Splitting the data into train/test</span>
<span class="ansi-white-fg">DEBUG:lightwood-2459: `split` runtime: 0.0 seconds</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing sequentially...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing encoder for year...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing encoder for mileage...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing encoder for tax...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing encoder for mpg...</span>
<span class="ansi-white-fg">DEBUG:dataprep_ml-2459:Preparing encoder for engineSize...</span>
<span class="ansi-green-fg">INFO:lightwood-2459:Categories Detected = 1</span>
<span class="ansi-green-fg">INFO:lightwood-2459:Categories Detected = 1</span>
<span class="ansi-green-fg">INFO:lightwood-2459:Categories Detected = 1</span>
<span class="ansi-white-fg">DEBUG:lightwood-2459: `prepare` runtime: 0.02 seconds</span>
<span class="ansi-green-fg">INFO:dataprep_ml-2459:Featurizing the data</span>
<span class="ansi-white-fg">DEBUG:lightwood-2459: `featurize` runtime: 0.56 seconds</span>
</pre></div></div>
</div>
<p>The splitter creates 3 data-splits, a “train”, “dev”, and “test” set. The <code class="docutils literal notranslate"><span class="pre">featurize</span></code> command from the predictor allows us to convert the cleaned data into features. We can access this as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pick a categorical column name</span>
<span class="n">col_name</span> <span class="o">=</span> <span class="s2">&quot;fuelType&quot;</span>

<span class="c1"># Get the encoded feature data</span>
<span class="n">enc_ft</span> <span class="o">=</span> <span class="n">ft_data</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_encoded_column_data</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#torch tensor (N_rows x N_output_dim)</span>

<span class="c1"># Get the original data from the dataset</span>
<span class="n">orig_data</span> <span class="o">=</span> <span class="n">ft_data</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_column_original_data</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span> <span class="c1">#pandas dataframe</span>

<span class="c1"># Create a pandas data frame to compare encoded data and original data</span>
<span class="n">compare_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">orig_data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">enc_ft</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;EncData&quot;</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">compare_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fuelType</th>
      <th>EncData</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Diesel</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Diesel</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Diesel</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Petrol</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Diesel</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can see what the label mapping is by inspecting our encoders as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Label Name -&gt; Label Number</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span><span class="o">.</span><span class="n">label_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;Unknown&#39;: 0, &#39;Diesel&#39;: 1, &#39;Petrol&#39;: 2, &#39;Hybrid&#39;: 3}
</pre></div></div>
</div>
<p>For each category above, the number associated in the dictionary is the label for each category. This means “Diesel” is always represented by a 1, etc.</p>
<p>With that, you’ve created your own custom Encoder that uses a rule-based approach! Please checkout more <a class="reference external" href="https://lightwood.io/tutorials.html">tutorials</a> for other custom approach guides.</p>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017-2024, MindsDB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>